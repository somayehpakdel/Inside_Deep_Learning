{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8c2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79042390",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039dd7ea",
   "metadata": {},
   "source": [
    "<img src=\"./images/04.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe87651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2018/4002559147.py:10: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from utils import train_network, View, set_seed, weight_reset\n",
    "import mlflow\n",
    "from torchinfo import summary\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2306505",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns07_4'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a32380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_07/mlruns07_1/143507330168611334', creation_time=1750415411076, experiment_id='143507330168611334', last_update_time=1750415411076, lifecycle_stage='active', name='Exercise07_1', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Exercise07_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878366d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e763208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf768bd",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencodDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, index):\n",
    "        # x, y = self.dataset.__getitem__(index)\n",
    "        x, y = self.dataset[index]\n",
    "        return  x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AutoencodDataset(torchvision.datasets.MNIST(\"./data\", train=True, transform=transforms.ToTensor(), download=True))\n",
    "test_data_xy = torchvision.datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_data_xx = AutoencodDataset(test_data_xy)\n",
    "batch_size = 128\n",
    "test_loader = DataLoader(test_data_xx, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e000614",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 28 * 28\n",
    "n = 64\n",
    "C =1\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the total number of trainable parameters in a PyTorch model.\n",
    "    Parameters are considered trainable if p.requires_grad is True.\n",
    "    \"\"\"\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return trainable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038ad82",
   "metadata": {},
   "source": [
    "### Non-Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(in_size, out_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_size, out_size),\n",
    "        nn.BatchNorm1d(out_size),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    get_layer(D, D//2),\n",
    "    get_layer(D//2, D//3),\n",
    "    nn.Linear(D//3, n),\n",
    ")\n",
    "\n",
    "auto_decoder = nn.Sequential(\n",
    "    get_layer(n, D//3),\n",
    "    get_layer(D//3, D//2),\n",
    "    nn.Linear(D//2, D),\n",
    "    nn.Sigmoid(),\n",
    "    View(-1, 1, 28, 28)\n",
    ")\n",
    "\n",
    "auto_encoder_non_sharing = nn.Sequential(\n",
    "    auto_encoder,\n",
    "    auto_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425913b4",
   "metadata": {},
   "source": [
    "### With Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7da1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposeLinear(nn.Module):\n",
    "    def __init__(self, linearlayer, bias=False):\n",
    "        super().__init__()\n",
    "        self.weight = linearlayer.weight\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(self.weight.shape[1]))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "    def forward(self, x):\n",
    "        return F.linear(x, self.weight.t(), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c92844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        out_size = layer.weight.shape[0] # nn.Linear weight is (out_features, in_features)\n",
    "    elif isinstance(layer, TransposeLinear):\n",
    "        # TransposeLinear's effective output size is the input size of the original Linear\n",
    "        out_size = layer.weight.shape[1] # original_linear_weight is (original_out, original_in)\n",
    "                                        # so original_in is shape[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported layer type for get_layer\")\n",
    "    return nn.Sequential(\n",
    "        layer, \n",
    "        nn.BatchNorm1d(out_size),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nn.Linear(D, D//2)\n",
    "layer_2 = nn.Linear(D//2, D//3)\n",
    "layer_3 = nn.Linear(D//3, n)\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    get_layer(layer_1),\n",
    "    get_layer(layer_2),\n",
    "    get_layer(layer_3)\n",
    "    )\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "    get_layer(TransposeLinear(layer_1)),\n",
    "    get_layer(TransposeLinear(layer_2)),\n",
    "    TransposeLinear(layer_3),\n",
    "    nn.Sigmoid(),\n",
    "    View(-1, 1, 28, 28)\n",
    "    )\n",
    "auto_encoder_weight_sharing = nn.Sequential(\n",
    "    encoder,\n",
    "    decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b15b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(linear_or_transposelinear_module):\n",
    "    # Determine the output size for BatchNorm1d\n",
    "    if isinstance(linear_or_transposelinear_module, nn.Linear):\n",
    "        out_features = linear_or_transposelinear_module.out_features\n",
    "    elif isinstance(linear_or_transposelinear_module, TransposeLinear):\n",
    "        # The output of TransposeLinear is the in_features of its original linear layer\n",
    "        # For this to work, TransposeLinear needs to know the original layer's dimensions.\n",
    "        # This requires a slight change in TransposeLinear init or how get_layer is used with it.\n",
    "        # Let's adjust TransposeLinear to explicitly take in_features/out_features\n",
    "        # or rely on its internal shared_weight's shape.\n",
    "        out_features = linear_or_transposelinear_module.output_features # New attribute in TransposeLinear\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported layer type for get_layer\")\n",
    "\n",
    "    return nn.Sequential(\n",
    "        linear_or_transposelinear_module,\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "class TransposeLinear(nn.Module):\n",
    "    def __init__(self, shared_weight_tensor, output_features, decoder_bias=True):\n",
    "        super().__init__()\n",
    "        # Store the shared_weight_tensor, but DO NOT register it as a parameter of this module.\n",
    "        # It's a reference to a parameter owned by an encoder layer.\n",
    "        self._shared_weight_ref = shared_weight_tensor # Use a different name to avoid confusion with nn.Module's 'weight'\n",
    "\n",
    "        # Store the output_features for BatchNorm in get_layer\n",
    "        self.output_features = output_features\n",
    "\n",
    "        # Create a *new, independent* bias for the decoder layer if requested.\n",
    "        # This bias *is* a parameter of this TransposeLinear module.\n",
    "        if decoder_bias:\n",
    "            self.decoder_bias = nn.Parameter(torch.empty(output_features))\n",
    "            nn.init.uniform_(self.decoder_bias, -0.1, 0.1)\n",
    "        else:\n",
    "            self.register_parameter('decoder_bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Access the shared weight tensor directly from the reference.\n",
    "        # Its transpose is (original_in_features, original_out_features)\n",
    "        return F.linear(x, self._shared_weight_ref.t(), self.decoder_bias)\n",
    "\n",
    "# 1. Define the core Linear layers for the encoder. These own the trainable weights.\n",
    "# These are the *only* Linear layers that should register weights in the model.\n",
    "encoder_linear_1 = nn.Linear(D, D // 3)  # 784 -> 261\n",
    "encoder_linear_2 = nn.Linear(D // 3, D // 2)  # 261 -> 392\n",
    "encoder_linear_3 = nn.Linear(D // 2, D)  # 392 -> 784\n",
    "\n",
    "# 2. Build the Encoder using these core linear layers wrapped in get_layer\n",
    "encoder = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    get_layer(encoder_linear_1),\n",
    "    get_layer(encoder_linear_2),\n",
    "    get_layer(encoder_linear_3)\n",
    ")\n",
    "\n",
    "# 3. Build the Decoder using TransposeLinear layers that *reference* the encoder's weights.\n",
    "decoder = nn.Sequential(\n",
    "    # Transpose of layer_3: Input D (784), Output D//2 (392)\n",
    "    get_layer(TransposeLinear(encoder_linear_3.weight, output_features=D // 2, decoder_bias=True)),\n",
    "\n",
    "    # Transpose of layer_2: Input D//2 (392), Output D//3 (261)\n",
    "    get_layer(TransposeLinear(encoder_linear_2.weight, output_features=D // 3, decoder_bias=True)),\n",
    "\n",
    "    # Transpose of layer_1: Input D//3 (261), Output D (784)\n",
    "    # This is the last linear layer before Sigmoid, no BatchNorm/ReLU\n",
    "    TransposeLinear(encoder_linear_1.weight, output_features=D, decoder_bias=True),\n",
    "\n",
    "    nn.Sigmoid(),\n",
    "    View(-1, 1, 28, 28)\n",
    ")\n",
    "\n",
    "auto_encoder_weight_sharing = nn.Sequential(\n",
    "    encoder,\n",
    "    decoder\n",
    ")\n",
    "summary(auto_encoder_weight_sharing, inpt_size=(batch_size, C, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f954f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "epochs = 50\n",
    "params = {\n",
    "    'device': device,\n",
    "    'loss_func': loss_func.__class__.__name__,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'auto_encoder_non_sharing': auto_encoder_non_sharing,\n",
    "    'auto_encoder_weight_sharing': auto_encoder_weight_sharing\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples in [1024, 8192, 32768, 60000]:\n",
    "    params['samples'] = samples\n",
    "    subset_indices = list(range(samples))\n",
    "    train_subset = Subset(train_data, subset_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    for experiment, model in models.items(): \n",
    "        model.apply(weight_reset)\n",
    "        params['experiment'] = experiment\n",
    "        optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "        with open('model_summary.txt', 'w') as f:\n",
    "            f.write(str(summary(model, inpt_size=(batch_size, C, 28, 28))))\n",
    "        with mlflow.start_run(nested=True, run_name=f'{experiment}_{samples}'):\n",
    "            mlflow.log('optimizer', optimizer.defaults)\n",
    "            mlflow.log_artifact('model_summary.txt')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            results = train_network(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                loss_func=loss_func,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=test_loader,\n",
    "                epochs=epochs,\n",
    "                device=device,                \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa30ada",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_train_loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9770",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_valid_loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0b3c7",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b7c47",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
