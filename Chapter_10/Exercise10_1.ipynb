{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551ad63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8408d1",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f30180",
   "metadata": {},
   "source": [
    "<img src=\"./images/01.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_10/utils.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import train_network, set_seed, accuracy_score_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415bcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c91a6",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6592df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:56<00:00, 175626.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 205896.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:06<00:00, 241701.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2723060.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargestDigitVariable(Dataset):\n",
    "    def __init__(self, dataset, max_to_sample=6):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.max_to_sample = max_to_sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, index):\n",
    "        how_many = np.random.randint(1, self.max_to_sample, size=1)[0]\n",
    "        selected = np.random.randint(1, len(self.dataset), size=how_many)\n",
    "        padding_needed = self.max_to_sample - how_many\n",
    "        x_new = torch.stack(\n",
    "            [self.dataset[i][0] for i in selected]\n",
    "            + [torch.zeros((1, 28, 28)) for _ in range(padding_needed)])\n",
    "        y_new = max([self.dataset[i][1] for i in selected])\n",
    "        return x_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 128\n",
    "\n",
    "largest_train = LargestDigitVariable(mnist_train)\n",
    "largest_test = LargestDigitVariable(mnist_test)\n",
    "T = largest_train.max_to_sample\n",
    "train_loader = DataLoader(largest_train, batch_size=B, shuffle=True)\n",
    "test_loader = DataLoader(largest_test, batch_size=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_fill(x, time_dimension=1, fill=0):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x: (B, ..., T, ...)\n",
    "    :type x: tensor\n",
    "    :param time_dimension: time dimention of x, defaults to 1\n",
    "    :type time_dimension: int, optional\n",
    "    :param fill: the constand use dto denote that an item, defaults to 0\n",
    "    :type fill: int, optional\n",
    "    \"\"\"\n",
    "    dimensions_to_sum_over = list(range(1, len(x.shape)))\n",
    "    if time_dimension in dimensions_to_sum_over:\n",
    "        dimensions_to_sum_over.remove(time_dimension)\n",
    "    with torch.no_grad():\n",
    "        mask = torch.sum((x != fill), dim=dimensions_to_sum_over) > 0\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03839d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotScore(nn.Module):\n",
    "\n",
    "    def __init__(self, H):\n",
    "        \"\"\"\n",
    "        H: the number of dimensions coming into the dot score. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.H = H\n",
    "    \n",
    "    def forward(self, states, context):\n",
    "        \"\"\"\n",
    "        states: (B, T, H) shape\n",
    "        context: (B, H) shape\n",
    "        output: (B, T, 1), giving a score to each of the T items based on the context \n",
    "        \n",
    "        \"\"\"\n",
    "        T = states.size(1)\n",
    "        scores = torch.bmm(states,context.unsqueeze(2)) / np.sqrt(self.H) #(B, T, H) -> (B, T, 1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralScore(nn.Module):\n",
    "\n",
    "    def __init__(self, H):\n",
    "        \"\"\"\n",
    "        H: the number of dimensions coming into the dot score. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w = nn.Bilinear(H, H, 1) #stores $W$\n",
    "    \n",
    "    def forward(self, states, context):\n",
    "        \"\"\"\n",
    "        states: (B, T, H) shape\n",
    "        context: (B, H) shape\n",
    "        output: (B, T, 1), giving a score to each of the T items based on the context \n",
    "        \n",
    "        \"\"\"\n",
    "        T = states.size(1)\n",
    "        #Repeating the values T times \n",
    "        context = torch.stack([context for _ in range(T)], dim=1) #(B, H) -> (B, T, H)\n",
    "        scores = self.w(states, context) #(B, T, H) -> (B, T, 1)\n",
    "        return scores        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttentionScore(nn.Module):\n",
    "\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.v = nn.Linear(H, 1) \n",
    "        self.w = nn.Linear(2*H, H)#2*H because we are going to concatenate two inputs\n",
    "    \n",
    "    def forward(self, states, context):\n",
    "        \"\"\"\n",
    "        states: (B, T, H) shape\n",
    "        context: (B, H) shape\n",
    "        output: (B, T, 1), giving a score to each of the T items based on the context \n",
    "        \n",
    "        \"\"\"\n",
    "        T = states.size(1)\n",
    "        #Repeating the values T times \n",
    "        context = torch.stack([context for _ in range(T)], dim=1) #(B, H) -> (B, T, H)\n",
    "        state_context_combined = torch.cat((states, context), dim=2) #(B, T, H) + (B, T, H)  -> (B, T, 2*H)\n",
    "        scores = self.v(torch.tanh(self.w(state_context_combined))) # (B, T, 2*H) -> (B, T, 1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64937a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    This helper module is used to apply the results of an attention mechanism to a set of inputs. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, states, attention_scores, mask=None):\n",
    "        \"\"\"\n",
    "        states: (B, T, H) shape giving the T different possible inputs\n",
    "        attention_scores: (B, T, 1) score for each item at each context\n",
    "        mask: None if all items are present. Else a boolean tensor of shape \n",
    "            (B, T), with `True` indicating which items are present / valid. \n",
    "            \n",
    "        returns: a tuple with two tensors. The first tensor is the final context\n",
    "        from applying the attention to the states (B, H) shape. The second tensor\n",
    "        is the weights for each state with shape (B, T, 1). \n",
    "        \"\"\"\n",
    "        \n",
    "        if mask is not None:\n",
    "            #set everything not present to a large negative value that will cause vanishing gradients \n",
    "            attention_scores[~mask] = -1000.0\n",
    "        #compute the weight for each score\n",
    "        weights = F.softmax(attention_scores, dim=1) #(B, T, 1) still, but sum(T) = 1\n",
    "    \n",
    "        final_context = (states*weights).sum(dim=1) #(B, T, D) * (B, T, 1) -> (B, D)\n",
    "        return final_context, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989e062",
   "metadata": {},
   "source": [
    "### Backbone: Fully_Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec945593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten2(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a vector of shape (A, B, C, D, E, ...)\n",
    "    and flattens everything but the first two dimensions, \n",
    "    giving a result of shape (A, B, C*D*E*...)\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), input.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmarterAttentionNetFC(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, out_size, score_net=None):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            Flatten2(),# Shape is now (B, T, D)\n",
    "            nn.Linear(input_size,hidden_size), #Shape becomes (B, T, H)\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "        )#returns (B, T, H)\n",
    "        \n",
    "        #Try changing this and see how the results change!\n",
    "        self.score_net = AdditiveAttentionScore(hidden_size) if (score_net is None) else score_net\n",
    "\n",
    "        self.apply_attn = ApplyAttention()\n",
    "        \n",
    "        self.prediction_net = nn.Sequential( #(B, H), \n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, out_size ) #(B, H)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        mask = get_mask_fill(input)\n",
    "\n",
    "        h = self.backbone(input) #(B, T, D) -> (B, T, H)\n",
    "\n",
    "        #h_context = torch.mean(h, dim=1) \n",
    "        #computes torch.mean but ignoring the masked out parts\n",
    "        #first add together all the valid items\n",
    "        h_context = (mask.unsqueeze(-1)*h).sum(dim=1)#(B, T, H) -> (B, H)\n",
    "        #then divide by the number of valid items, pluss a small value incase a bag was all empty\n",
    "        h_context = h_context/(mask.sum(dim=1).unsqueeze(-1)+1e-10)\n",
    "\n",
    "        scores = self.score_net(h, h_context) # (B, T, H) , (B, H) -> (B, T, 1)\n",
    "\n",
    "        final_context, _ = self.apply_attn(h, scores, mask=mask)\n",
    "\n",
    "        return self.prediction_net(final_context)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5726f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 256\n",
    "classes = 10\n",
    "D = 28 * 28\n",
    "attn_add_fc = SmarterAttentionNetFC(D, neurons, classes, score_net=AdditiveAttentionScore(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc3d9d",
   "metadata": {},
   "source": [
    "### Backbone: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90726ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "n_filters = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_layer(in_filters, out_filters, kernel_size=3):\n",
    "    \"\"\"\n",
    "    in_filters: how many channels are in the input to this layer\n",
    "    out_filters: how many channels should this layer output\n",
    "    kernel_size: how large should the filters of this layer be\n",
    "    \"\"\"\n",
    "    padding = kernel_size//2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_filters, out_filters, kernel_size, padding=padding), \n",
    "        nn.BatchNorm2d(out_filters),\n",
    "        nn.LeakyReLU(), # I'm not setting the leak value to anything just to make the code shorter. \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmarterAttentionNetCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, n_filters ,out_size, score_net=None):\n",
    "        super().__init__()\n",
    "        C, W, H = input_size\n",
    "        self.conv_backbone = nn.Sequential(\n",
    "            cnn_layer(C, n_filters, 3), #Shape becomes (B*T, n_filters, W, H)\n",
    "            cnn_layer(n_filters, n_filters, 3),  #Shape becomes (B*T, n_filters, W, H)\n",
    "            nn.MaxPool2d(2),\n",
    "            cnn_layer(n_filters, 2*n_filters, 3),  #Shape becomes (B*T, 2*n_filters, W//2, H//2)\n",
    "            # cnn_layer(2*n_filters, C, 3), #Shape becomes (B*T, C, W//2, H//2)\n",
    "            )#returns (B*T, C, W, H)\n",
    "        self.hidden_size = 2 * n_filters * (W//2) * (H//2)\n",
    "        #Try changing this and see how the results change!\n",
    "        self.score_net = AdditiveAttentionScore(self.hidden_size) if (score_net is None) else score_net\n",
    "\n",
    "        self.apply_attn = ApplyAttention()\n",
    "        \n",
    "        self.prediction_net = nn.Sequential( #(B, H), \n",
    "            nn.BatchNorm1d(self.hidden_size),\n",
    "            nn.Linear(self.hidden_size,self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_size),\n",
    "            nn.Linear(self.hidden_size, out_size ) #(B, H)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        B, T, C, W, H = input.shape\n",
    "\n",
    "        # Reshape for CNN: (B * T, C, W, H)\n",
    "        cnn_input = input.view( B*T, C, W, H)\n",
    "\n",
    "        # Pass through convolutional backbone\n",
    "        h = self.conv_backbone(cnn_input)\n",
    "        h = h.view(B, T, -1) #(B, T, D) -> (B, T, H)\n",
    "        mask = get_mask_fill(input)\n",
    "\n",
    "        #h_context = torch.mean(h, dim=1) \n",
    "        #computes torch.mean but ignoring the masked out parts\n",
    "        #first add together all the valid items\n",
    "        h_context = (mask.unsqueeze(-1)*h).sum(dim=1)#(B, T, H) -> (B, H)\n",
    "        #then divide by the number of valid items, pluss a small value incase a bag was all empty\n",
    "        h_context = h_context/(mask.sum(dim=1).unsqueeze(-1)+1e-10)\n",
    "\n",
    "        scores = self.score_net(h, h_context) # (B, T, H) , (B, H) -> (B, T, 1)\n",
    "\n",
    "        final_context, _ = self.apply_attn(h, scores, mask=mask)\n",
    "\n",
    "        return self.prediction_net(final_context)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_add_cnn = SmarterAttentionNetCNN((1, 28, 28), 32, classes,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0f4d9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43725e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "score_funcs = {\"Accuracy\": accuracy_score_wrapper}\n",
    "epochs = 10\n",
    "config = {\n",
    "    'device': device,\n",
    "    'loss_func': loss_func.__class__.__name__,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': B,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'fc': attn_add_fc,\n",
    "    'cnn': attn_add_cnn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:33<00:00, 33.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment, model in models.items():\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "    config['optimizer'] = optimizer.defaults\n",
    "    with open('model_summary.txt', 'w') as f:\n",
    "        f.write(str(summary(model, inpt_size=(B, T, 1, 28, 28))))\n",
    "    wandb.init(\n",
    "        project=\"Exercise10_1\",\n",
    "        name=experiment,\n",
    "        config=config\n",
    "    )\n",
    "    artifact = wandb.Artifact('model_summary', type='model_architecture')\n",
    "    artifact.add_file('model_summary.txt')\n",
    "    wandb.log_artifact(artifact)\n",
    "    results = train_network(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_func,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        score_funcs=score_funcs          \n",
    "    )\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
