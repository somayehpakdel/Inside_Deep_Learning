{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acf5e5",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2127945",
   "metadata": {},
   "source": [
    "<img src=\"./images/01.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b909bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import math\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from utils import train_network, set_seed, weight_reset, accuracy_score_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cbae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b00046",
   "metadata": {},
   "source": [
    "## Dataset and Dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_to_tuples(df):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, combines 'Title' and 'Description', and returns a list of tuples.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): input dataframe \n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple is (Class Index, Title + Description).\n",
    "    \"\"\"    \n",
    "    # Combine 'Title' and 'Description' columns\n",
    "    # Ensure both are strings to avoid errors during concatenation\n",
    "    df['combined_text'] = df['Title'].astype(str) + \" \" + df['Description'].astype(str)\n",
    "    \n",
    "    # Create the list of tuples\n",
    "    # Use .iloc to access rows by integer position for conversion to tuple\n",
    "    list_of_tuples = [(row['Class Index'], row['combined_text']) for index, row in df.iterrows()]\n",
    "    \n",
    "    return list_of_tuples\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'train.csv' is in the same directory as your script\n",
    "# Or provide the full path to your file\n",
    "train_data_tuples = process_csv_to_tuples(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "train_iter, test_iter = AG_NEWS(root='./data', split=('train', 'test'))\n",
    "train_dataset = list(train_iter)\n",
    "test_dataset = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f13f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "counter = Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17618a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(x):\n",
    "    return [vocab['<BOS>'] + [vocab(token) for token in tokenizer(x)] + vocab['<EOS>']]\n",
    "\n",
    "\n",
    "def label_transform(x):\n",
    "    return x-1\n",
    "\n",
    "print(text_transform(train_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "NUM_CLASS = len(np.unique([z[0] for z in train_dataset]))\n",
    "print(\"Vocab:\", VOCAB_SIZE)\n",
    "print(\"Num Classes:\", NUM_CLASS)\n",
    "padding_idx = vocab['<PAD>']\n",
    "embed_dim = 128\n",
    "B = 64\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(batch):\n",
    "    labels = [label_transform(z[0]) for z in batch]\n",
    "    texts =  [torch.tensor(text_transform(z[1]), dtype=torch.int64) for z in batch]\n",
    "    \n",
    "    max_len = max([text.size(0) for text in texts])\n",
    "    texts = [F.pad(text, (0, max_len-text.size(0)), value=padding_idx) for text in texts]\n",
    "    x = torch.stack(texts)\n",
    "    y = torch.tensor(labels, stype=torch.int64)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b325c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, collate_fn=pad_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=B, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c371b7d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
