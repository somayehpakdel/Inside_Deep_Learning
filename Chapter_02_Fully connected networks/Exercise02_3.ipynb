{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c70e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586/1799943160.py:3: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png', 'pdf')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8a8af",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114cc28",
   "metadata": {},
   "source": [
    "<img src='./images/03.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6cc0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d9073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/06 10:25:39 INFO mlflow.tracking.fluent: Experiment with name 'Exercise_1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_02/mlruns/773631873264077024', creation_time=1743922539674, experiment_id='773631873264077024', last_update_time=1743922539674, lifecycle_stage='active', name='Exercise_1', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment('Exercise_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7496c",
   "metadata": {},
   "source": [
    "This script addresses a modified version of the original problem from the book. The original task involved writing a function (resume_simple_network) that loads a model checkpoint from disk, restores both the optimizer and model states, and continues training to reach a specified total number of epochs.\n",
    "\n",
    "In this solution, I extended the problem to incorporate MLflow and Optuna skills. Instead of merely restoring a checkpoint, the script loads the best-performing model (logged with MLflow in the previous task) and resumes training with additional epochs. This approach leverages MLflow's experiment tracking and Optuna's hyperparameter optimization, enhancing reproducibility and automation in the model development process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723092c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import (train_network, accuracy_score_wrapper, \n",
    "                f1_score_wrapper, roc_auc_score_micro_wrapper, \n",
    "                weight_reset, set_seed)\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666daa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "set_seed(random_state)\n",
    "\n",
    "X_train, Y_train = make_moons(n_samples=8000, noise=0.4, random_state=random_state)\n",
    "X_valid, Y_valid = make_moons(n_samples=200, noise=0.4, random_state=random_state)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                            torch.tensor(Y_train, dtype=torch.long))\n",
    "valid_dataset = TensorDataset(torch.tensor(X_valid, dtype=torch.float32),\n",
    "                            torch.tensor(Y_valid, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5461e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data_df, close=True):\n",
    "    sns.lineplot(data_df, x='epoch', y='valid AUC', label='valid AUC')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('valid AUC')\n",
    "    plt.title('valid AUC')\n",
    "    fig = plt.gcf()\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae72d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_02/mlruns/218575834700796214/219aed50bb7f4f8cbe70429ade80c1a5/artifacts/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586/496767390.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_local_path)\n"
     ]
    }
   ],
   "source": [
    "run_id = '219aed50bb7f4f8cbe70429ade80c1a5' #best valid auc from previuos exercise\n",
    "checkpoint_local_path = mlflow.artifacts.download_artifacts(artifact_path=\"model.pth\", run_id=run_id)\n",
    "print(checkpoint_local_path)\n",
    "checkpoint = torch.load(checkpoint_local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3b704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RunData: metrics={'train AUC': 0.9327616875,\n",
       " 'train Acc': 0.85975,\n",
       " 'train F1': 0.860932077342588,\n",
       " 'train_loss': 0.33126768881970264,\n",
       " 'valid AUC': 0.9320999999999999,\n",
       " 'valid Acc': 0.835,\n",
       " 'valid F1': 0.819672131147541,\n",
       " 'valis_loss': 0.38746872544288635}, params={'activation': 'ReLU',\n",
       " 'batch_size': '172',\n",
       " 'device': 'cpu',\n",
       " 'epochs': '20',\n",
       " 'hidden_neurons': '483',\n",
       " 'layers': '7',\n",
       " 'learning_rate': '0.9838326800227287',\n",
       " 'loss_function': 'CrossEntropyLoss',\n",
       " 'optimizer': \"{'lr': 0.9838326800227287, 'momentum': 0, 'dampening': 0, \"\n",
       "              \"'weight_decay': 0, 'nesterov': False, 'maximize': False, \"\n",
       "              \"'foreach': None, 'differentiable': False, 'fused': None}\"}, tags={'mlflow.log-model.history': '[{\"run_id\": \"219aed50bb7f4f8cbe70429ade80c1a5\", '\n",
       "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
       "                             '\"2025-04-07 04:55:41.302860\", \"flavors\": '\n",
       "                             '{\"pytorch\": {\"model_data\": \"data\", '\n",
       "                             '\"pytorch_version\": \"2.4.1+cpu\", \"code\": null}, '\n",
       "                             '\"python_function\": {\"pickle_module_name\": '\n",
       "                             '\"mlflow.pytorch.pickle_module\", \"loader_module\": '\n",
       "                             '\"mlflow.pytorch\", \"python_version\": \"3.12.4\", '\n",
       "                             '\"data\": \"data\", \"env\": {\"conda\": \"conda.yaml\", '\n",
       "                             '\"virtualenv\": \"python_env.yaml\"}, \"config\": '\n",
       "                             '{\"device\": null}}}, \"model_uuid\": '\n",
       "                             '\"4472bbceae1742ada14b76b3fb761a73\"}]',\n",
       " 'mlflow.runName': 'trial: 12',\n",
       " 'mlflow.source.name': '/home/spakdel/miniconda3/envs/python3.12/lib/python3.12/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'spakdel'}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "client = MlflowClient()\n",
    "run_data = client.get_run(run_id).data\n",
    "run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7f09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'layers': '7',\n",
       " 'epochs': '20',\n",
       " 'activation': 'ReLU',\n",
       " 'optimizer': \"{'lr': 0.9838326800227287, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\",\n",
       " 'learning_rate': '0.9838326800227287',\n",
       " 'batch_size': '172',\n",
       " 'loss_function': 'CrossEntropyLoss',\n",
       " 'hidden_neurons': '483'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_data.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dd095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_02/utils.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file_load)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n",
      "2025/04/07 10:17:20 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/07 10:17:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.types import Schema, TensorSpec\n",
    "from mlflow.models import ModelSignature\n",
    "\n",
    "\n",
    "params = run_data.params\n",
    "epochs = 30\n",
    "in_features = 2\n",
    "out_features = 2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "params['device'] = device\n",
    "params['epochs'] = epochs\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "activation_functions = {\n",
    "'ReLU': nn.ReLU(),\n",
    "'Tanh': nn.Tanh(),\n",
    "'LeakyReLU': nn.LeakyReLU(),\n",
    "'Sigmoid': nn.Sigmoid()\n",
    "}\n",
    "sequential_layer = [\n",
    "    nn.Linear(in_features, int(params['hidden_neurons'])),\n",
    "    activation_functions[params['activation']]\n",
    "]\n",
    "for _ in range(int(params['layers'])):\n",
    "    sequential_layer.append(nn.Linear(int(params['hidden_neurons']), int(params['hidden_neurons'])))\n",
    "    sequential_layer.append(activation_functions[params['activation']])\n",
    "sequential_layer.append(nn.Linear(int(params['hidden_neurons']), out_features))\n",
    "\n",
    "model = nn.Sequential(*sequential_layer)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=float(params['learning_rate']))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=int(params['batch_size']),shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=int(params['batch_size']))\n",
    "\n",
    "with mlflow.start_run(nested=True, run_name='resume_best_auc'):\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    \n",
    "    with open (\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    fc_results = train_network(\n",
    "        model=model,\n",
    "        loss_func=loss_func,\n",
    "        train_loader=train_dataloader,\n",
    "        valid_loader=valid_dataloader,\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer,\n",
    "        score_funcs={'Acc':accuracy_score_wrapper, 'F1':f1_score_wrapper, 'AUC':roc_auc_score_micro_wrapper },\n",
    "        device=device,\n",
    "        checkpont_file_save='model.pth',\n",
    "        checkpoint_file_load=checkpoint_local_path\n",
    "    )\n",
    "    \n",
    "    input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 2))])\n",
    "    output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 2))])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "    mlflow.pytorch.log_model(model, \"model\", signature=signature)\n",
    "    mlflow.log_figure(plot_results(fc_results), \"valid_AUC.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
