{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed606d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e027b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586/1799943160.py:3: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png', 'pdf')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a77a59",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e87584",
   "metadata": {},
   "source": [
    "<img src='./images/08.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/08 14:06:53 INFO mlflow.tracking.fluent: Experiment with name 'Exercise_8' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_02/mlruns/476357225522364280', creation_time=1744108613358, experiment_id='476357225522364280', last_update_time=1744108613358, lifecycle_stage='active', name='Exercise_8', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment('Exercise_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spakdel/miniconda3/envs/python3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 2 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [01:07<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 4 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:36<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 8 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:22<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 16 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 32 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:08<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 64 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:05<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 128 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:04<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 256 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 512 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 1024 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig: 2048 batch sizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import (train_network, accuracy_score_wrapper, \n",
    "                f1_score_wrapper, roc_auc_score_micro_wrapper, \n",
    "                weight_reset, set_seed)\n",
    "from torchinfo import summary\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "from mlflow.models import ModelSignature\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "set_seed(random_state)\n",
    "\n",
    "X_train, Y_train = make_moons(n_samples=8000, noise=0.4, random_state=random_state)\n",
    "X_valid, Y_valid = make_moons(n_samples=200, noise=0.4, random_state=random_state)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                            torch.tensor(Y_train, dtype=torch.long))\n",
    "valid_dataset = TensorDataset(torch.tensor(X_valid, dtype=torch.float32),\n",
    "                            torch.tensor(Y_valid, dtype=torch.long))\n",
    "\n",
    "batch_sizes = [2 ** i for i in range(1, 12)]\n",
    "\n",
    "def plot_results(data_df, close=True):\n",
    "    sns.lineplot(data_df, x='epoch', y='valid AUC', label='valid AUC')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('valid AUC')\n",
    "    plt.title('valid AUC')\n",
    "    fig = plt.gcf()\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return fig\n",
    "\n",
    "def plot_results_batch_sizes(data_list, close=True):\n",
    "    sns.lineplot(x=batch_sizes, y=data_list)\n",
    "    plt.xlabel('batch sizes')\n",
    "    plt.ylabel('valid Acc')\n",
    "    plt.title('valid Acc per batch size')\n",
    "    # plt.xticks(batch_sizes)\n",
    "    fig = plt.gcf()\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return fig\n",
    "\n",
    "def plot_time_batch_sizes(data_list, close=True):\n",
    "    sns.lineplot(x=batch_sizes, y=data_list)\n",
    "    plt.xlabel('batch sizes')\n",
    "    plt.ylabel('total time')\n",
    "    plt.title('total time per batch size')\n",
    "    # plt.xticks(batch_sizes)\n",
    "    fig = plt.gcf()\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return fig\n",
    "\n",
    "epochs = 20\n",
    "in_features = 2\n",
    "out_features = 2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "params = {'device': device,\n",
    "        'epochs': epochs}\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2,  30),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(30,  30),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(30, 2),\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "params['optimizer'] = optimizer.defaults\n",
    "results_batch_sizes = []\n",
    "time_batch_sizes = []\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'trainig: {batch_size} batch sizes')\n",
    "    params['batch_size'] = batch_size\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "    with mlflow.start_run(nested=True, run_name=f'batch_size_{batch_size}'):\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        with open (\"model_summary.txt\", \"w\") as f:\n",
    "            f.write(str(summary(model)))\n",
    "        mlflow.log_artifact(\"model_summary.txt\")\n",
    "        # model.apply(weight_reset)\n",
    "        fc_results = train_network(\n",
    "            model=model,\n",
    "            loss_func=loss_func,\n",
    "            train_loader=train_dataloader,\n",
    "            valid_loader=valid_dataloader,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            score_funcs={'Acc':accuracy_score_wrapper, 'F1':f1_score_wrapper, 'AUC':roc_auc_score_micro_wrapper },\n",
    "            device=device,\n",
    "            # checkpoint_file_save='model.pth',\n",
    "            # checkpoint_every_x=10,\n",
    "        )\n",
    "        \n",
    "        # input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 2))])\n",
    "        # output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 2))])\n",
    "        # signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "        # mlflow.pytorch.log_model(model, \"model\", signature=signature)\n",
    "        mlflow.log_figure(plot_results(fc_results), \"valid_AUC.png\")\n",
    "    results_batch_sizes.append(fc_results['valid Acc'].iloc[-1])\n",
    "    time_batch_sizes.append(fc_results['total time'].iloc[-1])\n",
    "mlflow.log_figure(plot_results_batch_sizes(results_batch_sizes), 'valid_acc_per_batch_sizes.png')\n",
    "mlflow.log_figure(plot_time_batch_sizes(time_batch_sizes), 'time_per_batch_sizes.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0d0a2",
   "metadata": {},
   "source": [
    "<img src='./images/time_per_batch_sizes.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa443d",
   "metadata": {},
   "source": [
    "<img src='./images/valid_acc_per_batch_sizes.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bde67",
   "metadata": {},
   "source": [
    "<img src='./images/valid_auc_batch_size.png' width=800>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
