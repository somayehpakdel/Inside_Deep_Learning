{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72933003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cabd9",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d40d2",
   "metadata": {},
   "source": [
    "<img src='./images/06.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns03_6'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1251726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:07:16 INFO mlflow.tracking.fluent: Experiment with name 'Exercise_5' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/kaggle/working/mlruns/360360039686392042', creation_time=1744988836419, experiment_id='360360039686392042', last_update_time=1744988836419, lifecycle_stage='active', name='Exercise_5', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment('Exercise_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from utils import train_network, accuracy_score_wrapper, weight_reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C, H, W = 3, 32, 32\n",
    "num_pixels = H * W\n",
    "\n",
    "permutation = torch.randperm(num_pixels)\n",
    "\n",
    "def fixed_shuffle(img):\n",
    "    \"\"\"\n",
    "    Expects a tensor image of shape [C, H, W]\n",
    "    \"\"\"\n",
    "    # Flatten the spatial dimensions: for each channel, create a (H*W) vector.\n",
    "    # img.view(C, -1) will give a [C, H*W] tensor.\n",
    "    img_reshaped = img.view(C, -1)\n",
    "    \n",
    "    # Apply the fixed permutation to each channel\n",
    "    img_shuffled = img_reshaped[:, permutation]\n",
    "    \n",
    "    # Reshape back to [C, H, W]\n",
    "    return img_shuffled.view(C, H, W)\n",
    "\n",
    "# Now create a transform pipeline using Lambda\n",
    "shuffle_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(fixed_shuffle),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar_shuffletransform/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:04<00:00, 34.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_cifar_shuffletransform/cifar-10-python.tar.gz to ./data_cifar_shuffletransform\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train_shuffletransform = torchvision.datasets.CIFAR10(\n",
    "    './data_cifar_shuffletransform',\n",
    "    download=True,\n",
    "    transform=shuffle_transform,\n",
    "    # target_transform=lambda x: torch.tensor(x),\n",
    "    train=True,)\n",
    "cifar_test_shuffletransform = torchvision.datasets.CIFAR10(\n",
    "    './data_cifar_shuffletransform',\n",
    "    download=True,\n",
    "    transform=shuffle_transform,\n",
    "    # target_transform=lambda x: torch.tensor(x),\n",
    "    train=False,)\n",
    "\n",
    "cifar_train_loader_shuffle = DataLoader(\n",
    "    cifar_train_shuffletransform,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "cifar_test_loader_shuffle = DataLoader(\n",
    "    cifar_test_shuffletransform,\n",
    "    batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fd727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:04<00:00, 35.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_cifar/cifar-10-python.tar.gz to ./data_cifar\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = torchvision.datasets.CIFAR10(\n",
    "    './data_cifar',\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    train=True,)\n",
    "cifar_test = torchvision.datasets.CIFAR10(\n",
    "    './data_cifar',\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    train=False,)\n",
    "\n",
    "cifar_train_loader = DataLoader(\n",
    "    cifar_train,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "cifar_test_loader = DataLoader(\n",
    "    cifar_test,\n",
    "    batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581afb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = (cifar_train_loader, cifar_train_loader_shuffle)\n",
    "test_loaders = (cifar_test_loader, cifar_test_loader_shuffle)\n",
    "name_experiment = (\n",
    "    'build_model_cifar',\n",
    "    'build_model_cifar_shuffletransform',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "score_funcs = {\"Accuracy\": accuracy_score_wrapper}\n",
    "epochs = 20\n",
    "params = {\n",
    "    'device': device,\n",
    "    'loss_func': loss_func.__class__.__name__,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762cbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = cifar_train[0][0].shape[0]\n",
    "C = 3\n",
    "filter = 16\n",
    "K = 3\n",
    "# w = cifar_train[0][0].shape[1]\n",
    "# h = cifar_train[0][0].shape[2]\n",
    "w , h = 32, 32\n",
    "# classes = cifar_train[0][1].shape[0]\n",
    "classes = 10\n",
    "def build_model(num_conv_layers,\n",
    "                num_pool_layers,\n",
    "                num_hidden_layer=2, \n",
    "                init_hidden_size=512, \n",
    "                decay_factor=2,\n",
    "                activation=nn.ReLU(),\n",
    "                out_channels=32):\n",
    "    layers =[]\n",
    "    in_channels = C\n",
    "    # out_channels = 32\n",
    "    if num_pool_layers:\n",
    "        pool_interval = max(1, num_conv_layers // (num_pool_layers + 1))\n",
    "    else:\n",
    "        pool_interval = num_conv_layers + 1\n",
    "    \n",
    "    currnet_pool_rounds = 0\n",
    "    for i in range(num_conv_layers):\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            padding=3//2))\n",
    "        layers.append(activation)\n",
    "        in_channels = out_channels\n",
    "        if (i+1) % pool_interval == 0 and currnet_pool_rounds < num_pool_layers:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "            currnet_pool_rounds += 1\n",
    "            out_channels *= 2\n",
    "    final_w = w // (2 ** num_pool_layers)\n",
    "    final_h = h // (2 ** num_pool_layers)\n",
    "    fc_layers = []\n",
    "    # Compute the number of features after flattening.\n",
    "    in_features = in_channels * final_w * final_h\n",
    "\n",
    "    fc_layers.append(nn.Flatten())\n",
    "\n",
    "    if num_hidden_layer == 0:\n",
    "        # Directly classify without extra hidden layers.\n",
    "        fc_layers.append(nn.Linear(in_features, classes))\n",
    "    else:\n",
    "        # First FC layer: from flattened output to initial hidden size.\n",
    "        fc_layers.append(nn.Linear(in_features, init_hidden_size))\n",
    "        fc_layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Set the current hidden size that will be reduced in subsequent layers.\n",
    "        current_hidden_size = init_hidden_size\n",
    "\n",
    "        # Add additional hidden layers with decreasing size.\n",
    "        for layer in range(1, num_hidden_layer):\n",
    "            # Compute new hidden size with decay.\n",
    "            new_hidden_size = max(10, current_hidden_size // decay_factor)\n",
    "            fc_layers.append(nn.Linear(current_hidden_size, new_hidden_size))\n",
    "            fc_layers.append(nn.ReLU(inplace=True))\n",
    "            current_hidden_size = new_hidden_size\n",
    "\n",
    "        # Final classification layer from the last hidden dimension to the number of classes.\n",
    "        fc_layers.append(nn.Linear(current_hidden_size, classes))\n",
    "\n",
    "    classifier = nn.Sequential(*fc_layers)\n",
    "    model = nn.Sequential(*layers, classifier)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_conv_layers=4,\n",
    "        num_pool_layers=2,\n",
    "        num_hidden_layer=2, \n",
    "        init_hidden_size=512, \n",
    "        decay_factor=2,\n",
    "        activation=nn.ReLU(),\n",
    "        out_channels=256)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "params['optimizer'] = optimizer.defaults\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    f.write(str(summary(model)))\n",
    "for i in range(2):\n",
    "    print(i)\n",
    "    train_loader = train_loaders[i]\n",
    "    test_loader = test_loaders[i]    \n",
    "    with mlflow.start_run(nested=True, run_name=name_experiment[i]):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_artifact('model_summary.txt')\n",
    "        model.apply(weight_reset)\n",
    "        results = train_network(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            loss_func=loss_func,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=test_loader,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            score_funcs=score_funcs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025c61d",
   "metadata": {},
   "source": [
    "<img src=\"./images/valid_acc_shuffled.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d97a8",
   "metadata": {},
   "source": [
    "<img src=\"./images/valid_loss_shufled.png\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
