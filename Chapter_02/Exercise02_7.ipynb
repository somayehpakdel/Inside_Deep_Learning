{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb27e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586/1799943160.py:3: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png', 'pdf')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc38f6",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd10286",
   "metadata": {},
   "source": [
    "<img src='./images/07.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e355a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/07 17:42:03 INFO mlflow.tracking.fluent: Experiment with name 'Exercise_7' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_02/mlruns/904989942481923738', creation_time=1744035123832, experiment_id='904989942481923738', last_update_time=1744035123832, lifecycle_stage='active', name='Exercise_7', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment('Exercise_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0acf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spakdel/miniconda3/envs/python3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import (train_network, accuracy_score_wrapper, \n",
    "                f1_score_wrapper, roc_auc_score_micro_wrapper, \n",
    "                weight_reset, set_seed)\n",
    "from torchinfo import summary\n",
    "import optuna\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "from mlflow.models import ModelSignature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "set_seed(random_state)\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(data.data, dtype=torch.float32),\n",
    "    torch.tensor(data.target, dtype=torch.long)\n",
    "    )\n",
    "train_size = int(len(data.data) * 0.8)\n",
    "valid_size = len(data.data) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "in_features = dataset.tensors[0].shape[1]\n",
    "out_features = len(torch.unique(dataset.tensors[1]))\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "activation_functions = {\n",
    "'ReLU': nn.ReLU(),\n",
    "'Tanh': nn.Tanh(),\n",
    "'LeakyReLU': nn.LeakyReLU(),\n",
    "'Sigmoid': nn.Sigmoid()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b2440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achived value: 0.7472527472527473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:02<00:00,  6.90it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:04<00:00,  4.67it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.26it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:05<00:00,  3.62it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 12.07it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.25it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 achived value: 0.9154929577464789 with 18.3770% improvment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:02<00:00,  7.23it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:03<00:00,  6.06it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 13.50it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 15.94it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 14.28it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 11.05it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 15.34it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 15.42it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:02<00:00,  8.34it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:01<00:00, 10.20it/s]\n",
      "Epoch: 100%|██████████| 20/20 [00:02<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion trial: 7 with value 0.9154929577464789\n"
     ]
    }
   ],
   "source": [
    "def plot_results(data_df, close=True):\n",
    "    sns.lineplot(data_df, x='epoch', y='valid F1', label='valid F1')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('valid F1')\n",
    "    plt.title('valid F1')\n",
    "    fig = plt.gcf()\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return fig\n",
    "    \n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    winner = study.user_attrs.get('winner', None)\n",
    "    if winner is None:\n",
    "        print(f'Initial trial {frozen_trial.number} achived value: {frozen_trial.value}')\n",
    "    elif winner != study.best_value and study.best_value:   # second condition is for preventing zero devision\n",
    "        improvment_percent = (abs(winner - study.best_value) / abs(study.best_value)) * 100\n",
    "        print(f'Trial {frozen_trial.number} achived value: {frozen_trial.value} with {improvment_percent:.4f}% improvment')\n",
    "    study.set_user_attr('winner', study.best_value)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'batch_size': trial.suggest_int('batch_size', 16, 256),\n",
    "    'device': device,\n",
    "    'epochs' : epochs,\n",
    "    # 'optimizer': optimizer.defaults,\n",
    "    'loss_function': loss_func.__class__.__name__,\n",
    "    'learning_rate': trial.suggest_float('lr', 1e-8, 1, log=True),\n",
    "    'hidden_neurons': trial.suggest_int(\"neuron_per_layer\", in_features, 500),\n",
    "    'layers': trial.suggest_int(\"hidden_layers\", 1, 20),\n",
    "    'activation': trial.suggest_categorical(\"activation\", list(activation_functions.keys()))\n",
    "    }\n",
    "    sequential_layer = [\n",
    "        nn.Linear(in_features, params['hidden_neurons']),\n",
    "        activation_functions[params['activation']]\n",
    "    ]\n",
    "    for _ in range(params['layers']):\n",
    "        sequential_layer.append(nn.Linear(params['hidden_neurons'], params['hidden_neurons']))\n",
    "        sequential_layer.append(activation_functions[params['activation']])\n",
    "    sequential_layer.append(nn.Linear(params['hidden_neurons'], out_features))\n",
    "\n",
    "    model = nn.Sequential(*sequential_layer)\n",
    "    \n",
    "    # run_name = f'trial_lr_{params[\"learning_rate\"]:.8f}'\n",
    "    run_name = f'trial: {trial.number}'\n",
    "    with mlflow.start_run(nested=True, run_name=run_name):\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=params['learning_rate'])\n",
    "        params['optimizer'] = optimizer.defaults\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'],shuffle=True)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=params['batch_size'])\n",
    "        \n",
    "        with open (\"model_summary.txt\", \"w\") as f:\n",
    "            f.write(str(summary(model)))\n",
    "        mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "        model.apply(weight_reset)\n",
    "        fc_results = train_network(\n",
    "            model=model,\n",
    "            loss_func=loss_func,\n",
    "            train_loader=train_dataloader,\n",
    "            valid_loader=valid_dataloader,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            score_funcs={'Acc':accuracy_score_wrapper, 'F1':f1_score_wrapper, 'AUC':roc_auc_score_micro_wrapper },\n",
    "            device=device,\n",
    "            # checkpont_file_save='model.pth'\n",
    "        )\n",
    "        \n",
    "        # input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, in_features))])\n",
    "        # output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, out_features))])\n",
    "        # signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "        # mlflow.pytorch.log_model(model, \"model\", signature=signature)\n",
    "        mlflow.log_figure(plot_results(fc_results), \"valid_F1.png\")\n",
    "    return  fc_results['valid F1'].iloc[-1]\n",
    "\n",
    "epochs = 20\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20, callbacks=[champion_callback])\n",
    "champion_trial = study.best_trial\n",
    "print(f\"Champion trial: {champion_trial.number} with value {champion_trial.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a1bdb",
   "metadata": {},
   "source": [
    "<img src='./images/exercise07.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca9191",
   "metadata": {},
   "source": [
    "<img src='./images/train_valid_f1.png' width=800>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
