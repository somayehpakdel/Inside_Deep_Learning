{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a7b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f982b7",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f71fe",
   "metadata": {},
   "source": [
    "<img src=\"./images/08.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from torchinfo import summary\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from utils import set_seed, weight_reset\n",
    "from typing import DefaultDict, Any, Callable, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0575d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns08_8'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc06df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_07/mlruns07_1/143507330168611334', creation_time=1750415411076, experiment_id='143507330168611334', last_update_time=1750415411076, lifecycle_stage='active', name='Exercise07_1', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment('Exercise08_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f59cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfe04c",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a791e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f868f4",
   "metadata": {},
   "source": [
    "### Loose Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2145ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class2DetectLoose(Dataset):\n",
    "    \"\"\"This class is used to create a simple converstion of a dataset from a classification problem, to a detection problem. \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, toSample=3, canvas_size=100):\n",
    "        \"\"\"\n",
    "        dataset: tLoosehe source dataset to sample items from as the \"objects\" to detect\n",
    "        toSample: the maximum number of \"objects\" to put into any image\n",
    "        canvas_size: the width and height of the images to place objects inside of. \n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.toSample = toSample\n",
    "        self.canvas_size = canvas_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        final_size = self.canvas_size\n",
    "        #First, create a larger image that will store all the \"objects\" to detect\n",
    "        img_p = torch.zeros((final_size,final_size), dtype=torch.float32)\n",
    "        #Now we are going to sample up to self.toSample objects to place into the image\n",
    "        for _ in range(np.random.randint(1,self.toSample+1)):\n",
    "            \n",
    "            #Pick an object at random from the original dataset, and its label\n",
    "            img, label = self.dataset[np.random.randint(0,len(self.dataset))]\n",
    "            #Get the height and width of that image\n",
    "            _, img_h, img_w = img.shape\n",
    "            #Pick a random offset of the x and y axis, essentially placing the image at a random location\n",
    "            offsets = np.random.randint(0,final_size-np.max(img.shape),size=(4))\n",
    "            #Change the padding at the end to make sure we come out to a specific 100,100 shape\n",
    "            offsets[1] = final_size - img.shape[1] - offsets[0]\n",
    "            offsets[3] = final_size - img.shape[2] - offsets[2]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                img_p = img_p + F.pad(img, tuple(offsets))\n",
    "            #Lets craete the values for the \"boxes\"\n",
    "            #all of these are in absolute pixel locations\n",
    "            \n",
    "            #x_min determined by the randomly selected offset\n",
    "            xmin = offsets[0]\n",
    "            #x_max is the offset plus the image's width\n",
    "            xmax = offsets[0]+img_w\n",
    "            #y min/max follows the same pattern\n",
    "            ymin = offsets[2]\n",
    "            ymax = offsets[2]+img_h\n",
    "            #now we add to the box with the right label\n",
    "            boxes.append( [xmin, ymin, xmax, ymax] )\n",
    "            labels.append( label )\n",
    "\n",
    "            \n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        return img_p, target\n",
    "#Caption: This class defines a toy MNIST detector. Images from the MNIST dataset are placed at random locations in an image. The object detector will try to learn to predict where digits are, and what digit is at each location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c200adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch is going to contain a python list of objects. In our case, our data loader returns (Tensor, Dict) pairs\n",
    "    The FasterRCNN algorithm wants a List[Tensors] and a List[Dict]. So we will use this function to convert the \n",
    "    batch of data into the form we want, and then give it to the Dataloader to use\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for img, label in batch:\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d60edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loose = Class2DetectLoose(torchvision.datasets.MNIST(\"./data\", train=True, transform=transforms.ToTensor(), download=True))\n",
    "test_data_loose = Class2DetectLoose(torchvision.datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor(), download=True))\n",
    "batch_size = 128\n",
    "train_loader_loose = DataLoader(train_data_loose, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader_loose = DataLoader(test_data_loose, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: torch.Size([1, 100, 100])\n",
      "Sample Target Boxes:\n",
      " tensor([[14., 60., 42., 88.],\n",
      "        [23., 21., 51., 49.],\n",
      "        [29.,  1., 57., 29.]])\n",
      "Sample Target Labels:\n",
      " tensor([0, 1, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Number of images: 128\n",
      "  First image shape: torch.Size([1, 100, 100])\n",
      "  First target boxes shape: torch.Size([1, 4])\n",
      "  First target labels shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Example usage to verify\n",
    "if __name__ == '__main__':\n",
    "    sample_img, sample_target = train_data_loose[890]\n",
    "    print(\"Sample Image Shape:\", sample_img.shape)\n",
    "    print(\"Sample Target Boxes:\\n\", sample_target['boxes'])\n",
    "    print(\"Sample Target Labels:\\n\", sample_target['labels'])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Visualize a sample image with its tight bounding boxes\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Unsqueeze to remove batch dim if only one image, squeeze to remove channel dim\n",
    "    ax.imshow(sample_img.squeeze(0).numpy(), cmap='gray')\n",
    "    for i in range(sample_target['boxes'].shape[0]):\n",
    "        box = sample_target['boxes'][i].numpy()\n",
    "        label = sample_target['labels'][i].item()\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(xmin, ymin, str(label), color='blue', fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=0))\n",
    "    plt.title(\"Sample Image with Tight Bounding Boxes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd7c9e",
   "metadata": {},
   "source": [
    "### Tight Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8eef61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class2DetectTight(Dataset):\n",
    "    \"\"\"This class is used to create a simple converstion of a dataset from a classification problem, to a detection problem. \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, toSample=3, canvas_size=100):\n",
    "        \"\"\"\n",
    "        dataset: the source dataset to sample items from as the \"objects\" to detect\n",
    "        toSample: the maximum number of \"objects\" to put into any image\n",
    "        canvas_size: the width and height of the images to place objects inside of.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.toSample = toSample\n",
    "        self.canvas_size = canvas_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        final_size = self.canvas_size\n",
    "        #First, create a larger image that will store all the \"objects\" to detect\n",
    "        img_p = torch.zeros((1, final_size, final_size), dtype=torch.float32) # Changed to 1 channel for consistency\n",
    "        #Now we are going to sample up to self.toSample objects to place into the image\n",
    "        for _ in range(np.random.randint(1,self.toSample+1)):\n",
    "\n",
    "            #Pick an object at random from the original dataset, and its label\n",
    "            img, label = self.dataset[np.random.randint(0,len(self.dataset))]\n",
    "            #Get the height and width of that image\n",
    "            # _, img_h, img_w = img.shape # We will get these from the tight bbox now\n",
    "\n",
    "            # --- MODIFICATION START ---\n",
    "            # Find the tight bounding box for the digit in the original MNIST image\n",
    "            # Assuming img is 1 channel (C, H, W) where C=1\n",
    "            non_zero_coords = torch.nonzero(img.squeeze(0)) # Get (row, col) of non-zero pixels\n",
    "            if non_zero_coords.numel() == 0: # Handle cases where the digit might be completely black (shouldn't happen with MNIST)\n",
    "                continue # Skip this digit if it's empty\n",
    "\n",
    "            y_min_digit = torch.min(non_zero_coords[:, 0]).item()\n",
    "            y_max_digit = torch.max(non_zero_coords[:, 0]).item()\n",
    "            x_min_digit = torch.min(non_zero_coords[:, 1]).item()\n",
    "            x_max_digit = torch.max(non_zero_coords[:, 1]).item()\n",
    "\n",
    "            # Calculate the dimensions of the tight digit image\n",
    "            tight_img_h = y_max_digit - y_min_digit + 1\n",
    "            tight_img_w = x_max_digit - x_min_digit + 1\n",
    "\n",
    "            # Crop the digit image to its tight bounding box\n",
    "            tight_img = img[:, y_min_digit:y_max_digit+1, x_min_digit:x_max_digit+1]\n",
    "            # --- MODIFICATION END ---\n",
    "\n",
    "\n",
    "            #Pick a random offset of the x and y axis for placing the tight_img\n",
    "            # The available space for placement is canvas_size - tight_img_dim\n",
    "            offset_y = np.random.randint(0, final_size - tight_img_h + 1)\n",
    "            offset_x = np.random.randint(0, final_size - tight_img_w + 1)\n",
    "\n",
    "            # Calculate padding for the tightly cropped image\n",
    "            # pad_left, pad_right, pad_top, pad_bottom\n",
    "            pad_left = offset_x\n",
    "            pad_right = final_size - offset_x - tight_img_w\n",
    "            pad_top = offset_y\n",
    "            pad_bottom = final_size - offset_y - tight_img_h\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Apply padding to the tight_img and add it to the canvas\n",
    "                img_p += F.pad(tight_img, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "\n",
    "            # Let's create the values for the \"boxes\"\n",
    "            # These are in absolute pixel locations on the final_size canvas\n",
    "            xmin = offset_x\n",
    "            xmax = offset_x + tight_img_w\n",
    "            ymin = offset_y\n",
    "            ymax = offset_y + tight_img_h\n",
    "\n",
    "            #now we add to the box with the right label\n",
    "            boxes.append( [xmin, ymin, xmax, ymax] )\n",
    "            labels.append( label )\n",
    "\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # Ensure the final image is 1-channel (if it wasn't already)\n",
    "        return img_p, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85882ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for img, label in batch:\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tight = Class2DetectTight(torchvision.datasets.MNIST(\"./data\", train=True, transform=transforms.ToTensor(), download=True))\n",
    "test_data_tight = Class2DetectTight(torchvision.datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor(), download=True))\n",
    "train_loader_tight = DataLoader(train_data_tight, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader_tight = DataLoader(test_data_tight, batch_size=128, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016efd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: torch.Size([1, 100, 100])\n",
      "Sample Target Boxes:\n",
      " tensor([[ 6., 55., 14., 75.],\n",
      "        [17., 22., 31., 42.]])\n",
      "Sample Target Labels:\n",
      " tensor([1, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Number of images: 128\n",
      "  First image shape: torch.Size([1, 100, 100])\n",
      "  First target boxes shape: torch.Size([2, 4])\n",
      "  First target labels shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Example usage to verify\n",
    "if __name__ == '__main__':\n",
    "    sample_img, sample_target = train_data_tight[890]\n",
    "    print(\"Sample Image Shape:\", sample_img.shape)\n",
    "    print(\"Sample Target Boxes:\\n\", sample_target['boxes'])\n",
    "    print(\"Sample Target Labels:\\n\", sample_target['labels'])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Visualize a sample image with its tight bounding boxes\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Unsqueeze to remove batch dim if only one image, squeeze to remove channel dim\n",
    "    ax.imshow(sample_img.squeeze(0).numpy(), cmap='gray')\n",
    "    for i in range(sample_target['boxes'].shape[0]):\n",
    "        box = sample_target['boxes'][i].numpy()\n",
    "        label = sample_target['labels'][i].item()\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(xmin, ymin, str(label), color='blue', fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=0))\n",
    "    plt.title(\"Sample Image with Tight Bounding Boxes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64809262",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "classes = 10\n",
    "n_filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_layer(in_filters, out_filters, kernel_size=3):\n",
    "    \"\"\"\n",
    "    in_filters: how many channels are in the input to this layer\n",
    "    out_filters: how many channels should this layer output\n",
    "    kernel_size: how large should the filters of this layer be\n",
    "    \"\"\"\n",
    "    padding = kernel_size//2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_filters, out_filters, kernel_size, padding=padding), \n",
    "        nn.BatchNorm2d(out_filters),\n",
    "        nn.LeakyReLU(), # I'm not setting the leak value to anything just to make the code shorter. \n",
    "    )\n",
    "backbone = nn.Sequential(\n",
    "    cnn_layer(C, n_filters),    \n",
    "    cnn_layer(n_filters, n_filters),\n",
    "    cnn_layer(n_filters, n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnn_layer(n_filters, 2*n_filters),\n",
    "    cnn_layer(2*n_filters, 2*n_filters),\n",
    "    cnn_layer(2*n_filters, 2*n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnn_layer(2*n_filters, 4*n_filters),\n",
    "    cnn_layer(4*n_filters, 4*n_filters),\n",
    ")\n",
    "#Let Faster RCNN know exactly how many output channels to expect\n",
    "backbone.out_channels = n_filters*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many proposals $k$ should be generated? Every aspect ration will be one, and the process will be repeated for multiple image sizes \n",
    "anchor_generator = AnchorGenerator(sizes=((32),), aspect_ratios=((1.0),)) #To make this run faster, we are telling PyTorch to look for only square images that are 32 x 32 in size\n",
    "\n",
    "#Tell PyTorch to use the final output of the backbone as the featuremap (['0']), use adaptive pooling down to a 7x7 grid (output_size=7)\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "#sampling_ratio is poorly named, and controls details on how the RoI grabs slices of the feature map when a fractional pixel location is predicted (e.g., 5.8 instead of 6). We are not going to go into those low level details, 2 is a reasonable default for most work. \n",
    "        \n",
    "#Now we can create the FasterRCNN object. We give it the backbone network, number of classes, min & max size to process images at (we know all our images at 100 pixels), a mean and standard deviation to subtract from the images, and the anchor generation (RPN) and RoI objects\n",
    "model = FasterRCNN(backbone, num_classes=10, image_mean = [0.5], image_std = [0.229], min_size=100, max_size=100, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477ffb5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fda728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "params = {\n",
    "    'device': device,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(optimizer, metric_calculator ,train_loader, test_loader=None):\n",
    "    results = defaultdict(list)\n",
    "    total_train_time = 0\n",
    "\n",
    "    # --- Main Training and Validation Loop ---\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        results['epoch'].append(epoch)\n",
    "        \n",
    "        # ===================================\n",
    "        #           TRAINING\n",
    "        # ===================================\n",
    "        model.train() # Set model to training mode\n",
    "        running_train_loss = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            inputs = [img.to(device) for img in inputs]\n",
    "            labels = [{k: v.to(device) for k, v in t.items()} for t in labels]\n",
    "\n",
    "            # Get losses\n",
    "            loss_dict = model(inputs, labels)\n",
    "            loss = sum(l for l in loss_dict.values())\n",
    "            \n",
    "            # Backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss.append(loss.item())\n",
    "\n",
    "        # --- Log Training Results for Epoch ---\n",
    "        total_train_time += (time.time() - start_time)\n",
    "        avg_train_loss = np.mean(running_train_loss)\n",
    "        results['train loss'].append(avg_train_loss)\n",
    "        results['total time'].append(total_train_time)\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "        mlflow.log_metric('Time', total_train_time, step=epoch)\n",
    "\n",
    "        # ===================================\n",
    "        #           VALIDATION\n",
    "        # ===================================\n",
    "        if test_loader is not None:\n",
    "            metric_calculator.reset() # Reset metrics before each validation run\n",
    "            running_valid_loss = []\n",
    "            \n",
    "            with torch.no_grad(): # Disable gradient calculations\n",
    "                for inputs, labels in tqdm(test_loader, desc=\"Validating\", leave=False):\n",
    "                    inputs = [img.to(device) for img in inputs]\n",
    "                    labels = [{k: v.to(device) for k, v in t.items()} for t in labels]\n",
    "                    \n",
    "                    # 1. Get validation loss (model in .train() mode)\n",
    "                    model.train()\n",
    "                    loss_dict = model(inputs, labels)\n",
    "                    loss = sum(l for l in loss_dict.values())\n",
    "                    running_valid_loss.append(loss.item())\n",
    "\n",
    "                    # 2. Get predictions for metrics (model in .eval() mode)\n",
    "                    model.eval()\n",
    "                    predictions = model(inputs)\n",
    "                    \n",
    "                    # Update the metric calculator with the new predictions and labels\n",
    "                    metric_calculator.update(predictions, labels)\n",
    "\n",
    "            # --- Log Validation Results for Epoch ---\n",
    "            avg_valid_loss = np.mean(running_valid_loss)\n",
    "            results['valid loss'].append(avg_valid_loss)\n",
    "            mlflow.log_metric(\"valid_loss\", avg_valid_loss, step=epoch)\n",
    "\n",
    "            # Compute and log the final mAP scores\n",
    "            metrics = metric_calculator.compute()\n",
    "            results['valid_mAP'].append(metrics['map'].item())\n",
    "            mlflow.log_metric(\"valid_mAP\", metrics['map'].item(), step=epoch)\n",
    "            mlflow.log_metric(\"valid_mAP_50\", metrics['map_50'].item(), step=epoch)\n",
    "            mlflow.log_metric(\"valid_mAP_75\", metrics['map_75'].item(), step=epoch)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Valid Loss: {avg_valid_loss:.4f} | mAP: {metrics['map'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d26ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ('losse boxes', 'tight boxes')\n",
    "train_datasets = (train_data_loose, train_data_tight)\n",
    "train_loaders = (train_loader_loose, train_loader_tight)\n",
    "test_loaders = (test_loader_loose, test_loader_tight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, experiment in enumerate(experiments):\n",
    "    print(experiment)\n",
    "    train_loader = train_loaders[i]\n",
    "    test_loader = test_loaders[i]\n",
    "    train_dataset = train_datasets[i]\n",
    "    model.apply(weight_reset)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    params['optimizer'] = optimizer.defaults\n",
    "\n",
    "    # --- Metric Calculator ---\n",
    "    # This object will accumulate predictions and targets to calculate mAP\n",
    "    metric_calculator = MeanAveragePrecision(box_format=\"xyxy\")\n",
    "\n",
    "    with mlflow.start_run(run_name=experiment):\n",
    "        mlflow.log_artifact('model_summary.txt')\n",
    "        mlflow.log_params(params)\n",
    "        with open('model_summary.txt', 'w') as f:\n",
    "            f.write(str(summary(model, inpt_size=(batch_size,tuple(train_dataset[0][0].shape)))))\n",
    "        train_network(\n",
    "            optimizer=optimizer,\n",
    "            metric_calculator=metric_calculator,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d46389",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de649fe",
   "metadata": {},
   "source": [
    "### Why Tight Boxes are Better\n",
    "\n",
    "#### Reduced Background Noise:\n",
    "\n",
    "- Loose Boxes: When the ground-truth box is loose, it contains a large amount of empty background pixels. The model is forced to learn that these irrelevant black pixels are part of the \"digit\" object. This creates a noisy, weak signal for both classification and box regression.\n",
    "\n",
    "- Tight Boxes: The ground-truth box contains almost exclusively pixels belonging to the digit. This provides a clean, strong signal, allowing the model to learn the digit's actual features much more effectively.\n",
    "\n",
    "#### Accurate Intersection over Union (IoU) Calculation:\n",
    "\n",
    "- Loose Boxes: A major problem arises during evaluation. Your model might predict a perfectly tight box around a digit. However, when this excellent prediction is compared to the large, loose ground-truth box, the IoU score will be low. The model gets penalized for being more accurate than the label. This makes the training objective for the box regressor confusing and results in a lower mAP score that doesn't reflect the model's true ability.\n",
    "\n",
    "- Tight Boxes: When the ground truth is also tight, a good prediction results in a high IoU. The training signal is correct, and the evaluation metric (mAP) accurately reflects the model's localization performance.\n",
    "\n",
    "#### Expected Results on Test Images\n",
    "When you visualize the predictions on test images:\n",
    "\n",
    "- Model Trained on Loose Boxes: The predicted bounding boxes will likely be sloppy and oversized. They will mimic the loose boxes seen during training. Confidence scores may be lower because the model is less certain about the noisy features.\n",
    "\n",
    "- Model Trained on Tight Boxes: The predicted bounding boxes will be visibly more precise and will snugly fit the digits. The localization will be far superior, and confidence scores will likely be higher. The overall result will look much more professional and accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
