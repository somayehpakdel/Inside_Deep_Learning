{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544363bc",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b6692",
   "metadata": {},
   "source": [
    "<img src=\"./images/04.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815800c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_06/utils.py:6: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "from torchinfo import summary\n",
    "from utils import train_network, accuracy_score_wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb13c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = './mlruns06_4'\n",
    "mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/08 15:29:31 INFO mlflow.tracking.fluent: Experiment with name 'Exercise06_2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/spakdel/my_projects/Books/Inside-Deep-Learning/Exercises_InsideDeepLearning/Chapter_06/mlruns06_2/743342736727177787', creation_time=1749383971503, experiment_id='743342736727177787', last_update_time=1749383971503, lifecycle_stage='active', name='Exercise06_2', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment('Exercise06_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f4fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic=True\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7fc8",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44926661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e14a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = train_data.data.shape[1] \n",
    "H = train_data.data.shape[2]\n",
    "D = W * H\n",
    "C = 1\n",
    "classes = len(torch.unique(train_data.targets))\n",
    "n_filters = 32\n",
    "hidden_neurons = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8570f1",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac5503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockE(nn.Module):\n",
    "    def __init__(self, in_featurs, out_featurs, activation=nn.LeakyReLU(.1)):\n",
    "        super().__init__()\n",
    "        self.F = nn.Sequential(\n",
    "            nn.Linear(in_featurs, out_featurs),\n",
    "            nn.BatchNorm1d(out_featurs),\n",
    "            activation,\n",
    "            nn.Linear(out_featurs, out_featurs),\n",
    "            nn.BatchNorm1d(out_featurs),\n",
    "            activation\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0834d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_bn(D, hidden_neurons, num_layers, classes):\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(D, hidden_neurons), nn.BatchNorm1d(hidden_neurons), nn.LeakyReLU(.1),\n",
    "        *[nn.Sequential(\n",
    "            nn.Linear(hidden_neurons, hidden_neurons),\n",
    "            nn.BatchNorm1d(hidden_neurons),\n",
    "            nn.LeakyReLU(.1))\n",
    "            for _ in range(num_layers)],\n",
    "        nn.Linear(hidden_neurons, classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513fa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_resblockE(D, hidden_neurons, num_layers, classes):\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(D, hidden_neurons), nn.BatchNorm1d(hidden_neurons), nn.LeakyReLU(.1),\n",
    "        *[ResidualBlockE(hidden_neurons, hidden_neurons) for _ in range(num_layers//2)],\n",
    "        nn.Linear(hidden_neurons, classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17646a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "score_funcs = {\"Accuracy\": accuracy_score_wrapper}\n",
    "epochs = 10\n",
    "params = {\n",
    "    'device': device,\n",
    "    'loss_func': loss_func.__class__.__name__,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e83906",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_models = {\n",
    "    'fc_bn': fc_bn,\n",
    "    'fc_resblockE': fc_resblockE,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2af256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment, fc_model in type_models.items():\n",
    "    print('experiment: ', experiment)\n",
    "    for num_layers in range(2, 21, 2):  \n",
    "        print(f\"num_layers: {num_layers} \")\n",
    "        model = fc_model(D, hidden_neurons, num_layers, classes)\n",
    "        optimizer = torch.optim.AdamW(model.parameters())\n",
    "        params['optimizer'] = optimizer.defaults\n",
    "        params['num_layers'] = num_layers\n",
    "        params['experiment'] = experiment\n",
    "        with open('model_summary.txt', 'w') as f:\n",
    "            f.write(str(summary(model, input_size=(batch_size, C, W, H))))\n",
    "        with mlflow.start_run(nested=True, run_name=experiment+f'{num_layers}'):\n",
    "            mlflow.log_artifact('model_summary.txt')\n",
    "            mlflow.log_params(params)\n",
    "            fc_results = train_network(\n",
    "                model=model,\n",
    "                loss_func=loss_func,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=test_loader,\n",
    "                # test_loader=test_loader,\n",
    "                epochs=epochs,\n",
    "                optimizer=optimizer,\n",
    "                score_funcs=score_funcs,\n",
    "                device=device,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540cf22",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_train_acc_selected.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e482b2",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_train_loss_selected.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f9a14",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_valid_acc_selected.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9dbb6",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_valid_loss_selected.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ef5a0",
   "metadata": {},
   "source": [
    "<img src=\"./images/E4_time_selected.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
